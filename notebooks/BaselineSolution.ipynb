{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e372475",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "Goal of this notebook is to implement simple solution and get score to propose our initial hypothesys. As a baseline I will use idea of removing words that correlate with high-toxic score.  \n",
    "\n",
    "Prerequirements to run this notebook:\n",
    "* download all libraries mentioned in `requirements.txt`\n",
    "* download [filtered ParaNMT-detox corpus dataset](https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip)\n",
    "* unzip archive via graphical interface (ui.py) or just by hands to a directory `../data/raw/filtered_paranmt/filtered.tsv`\n",
    "\n",
    "Basic information about the dataset\n",
    "* `reference` (str) - First item from the pair\n",
    "* `ref_tox` (float) - toxicity level of reference text\n",
    "* `translation` (str) - second item from the pair - paraphrazed version of the reference\n",
    "* `trn_tox` (float) - toxicity level of translation text\n",
    "* `similarity` (float) - cosine similarity of the texts\n",
    "* `lenght_diff` (float) - relative length difference between texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49528963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('../data/raw/filtered_paranmt/filtered.tsv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef7681",
   "metadata": {},
   "source": [
    "# Preprocessing step\n",
    "\n",
    "I will use techniques 1.1-1.3 (from `LearningDataset` notebook) for preprocessing. Main idea is to split translation/reference to toxic/non-toxic columns (as they are mixed) and introduce some threasholds on simmilarity and toxicity.\n",
    "\n",
    "\n",
    "1.1 During data preprocessing introduce new features `toxic` and `non-toxic` based on `ref_tox` and `trn_tox` scores.\\\n",
    "1.2 Introduce `toxisity_difference` threashold duting preprocessing.\\\n",
    "1.3 Tune which `simmilarity` value to consider in order to save sence of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90d4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxisity_difference = 0.75\n",
    "simmilarity_rate = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd65a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries passed: 72.61%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tox_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tox_score\n",
       "0  if Alkar floods her with her mental waste, it ...   0.981983\n",
       "1                        you're becoming disgusting.   0.999039\n",
       "2                      well, we can spare your life.   0.985068\n",
       "3                       monkey, you have to wake up.   0.994215\n",
       "4                         I have orders to kill her.   0.999348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split words to toxic & non-toxic based on rate [1.1]\n",
    "tox_queries = []\n",
    "ntox_queries = []\n",
    "\n",
    "for tox_query, ntox_query, sim, len_diff, tox, ntox in df.values:\n",
    "    if tox < ntox:\n",
    "        tox, ntox = ntox, tox\n",
    "        tox_query, ntox_query = ntox_query, tox_query \n",
    "    \n",
    "    # add threasholds on toxisity_difference [1.2] and simmilarity rate [1.3]\n",
    "    if (tox - ntox) >= toxisity_difference and sim >= simmilarity_rate:\n",
    "        tox_queries.append((tox_query, tox))\n",
    "        ntox_queries.append((ntox_query, ntox))\n",
    "\n",
    "print(f'Queries passed: {round(100 * len(tox_queries) / df.shape[0], 2)}%')\n",
    "\n",
    "# convert processed data to dataframes\n",
    "tox = pd.DataFrame(tox_queries, columns=['message', 'tox_score'])\n",
    "non_tox = pd.DataFrame(ntox_queries, columns=['message', 'tox_score'])\n",
    "\n",
    "tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1908f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cutefluffyfox/.local/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tox_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[if, alkar, floods, her, with, her, mental, wa...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[you, 're, becoming, disgusting, .]</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[well, ,, we, can, spare, your, life, .]</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[monkey, ,, you, have, to, wake, up, .]</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, orders, to, kill, her, .]</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tox_score\n",
       "0  [if, alkar, floods, her, with, her, mental, wa...   0.981983\n",
       "1                [you, 're, becoming, disgusting, .]   0.999039\n",
       "2           [well, ,, we, can, spare, your, life, .]   0.985068\n",
       "3            [monkey, ,, you, have, to, wake, up, .]   0.994215\n",
       "4                [i, have, orders, to, kill, her, .]   0.999348"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# tokenize\n",
    "tox['message'] = tox.message.str.lower().apply(word_tokenize)\n",
    "non_tox['message'] = non_tox.message.str.lower().apply(word_tokenize)\n",
    "\n",
    "tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa15c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 755090\n",
      "Test size: 83900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tox\n",
    "y = non_tox\n",
    "\n",
    "# split data to train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('Train size:', X_train.size)\n",
    "print('Test size:', X_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c6e60",
   "metadata": {},
   "source": [
    "# Model itself \n",
    "\n",
    "For baseline model I suggested an idea of simple toxic-word remover. For that we already explored how to determine such words `1.4` and `1.6` (in `LearningDataset` notebook). Basically we can calculate mean and standart deviation for each sentence word appears in. With that, we can define threashold of toxicity (mean) and out certainty (std). With this idea we suppose to get all curse words and words with the only toxic meaning. For words that could be both toxic and non-toxic (e.g. kill) std ideally should be high enough, so they won't be included in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca60407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ToxicWordRemover:\n",
    "    def __init__(self, std: float = 0.1, mean: float = 0.9, n_occurences: int = 20):\n",
    "        self.word_tox = dict()\n",
    "        self.toxic_words = set()\n",
    "        self.update_params(std=std, mean=mean, n_occurences=n_occurences, recalculate=False)\n",
    "    \n",
    "    def fit(self, toxic: pd.DataFrame, non_toxic: pd.DataFrame, with_scores: float = False):\n",
    "        # check if scores exists, if no, add them\n",
    "        if not with_scores:\n",
    "            toxic['tox_score'] = 1\n",
    "            non_tox['tox_score'] = 0\n",
    "        \n",
    "        # combine sentences\n",
    "        combined = pd.concat([toxic, non_toxic])\n",
    "        \n",
    "        # calculate mean/std toxisity levels for each word (from most popular one)\n",
    "        word_tox = dict()\n",
    "\n",
    "        # iterate through all tokens and add their' toxisity value to dict\n",
    "        for words, tox_level in combined.values:\n",
    "            for word in words:\n",
    "                \n",
    "                if word not in word_tox:\n",
    "                    word_tox[word] = []\n",
    "\n",
    "                word_tox[word].append(tox_level)\n",
    "        \n",
    "        # convert all values to numpy for faster statistics\n",
    "        for word in word_tox:\n",
    "            word_tox[word] = np.array(word_tox[word])\n",
    "        \n",
    "        # save raw data for recalculation purposes\n",
    "        self.word_tox = word_tox\n",
    "        \n",
    "        # determine toxic words and save them\n",
    "        self.__determine_toxic()\n",
    "        \n",
    "    \n",
    "    def predict(self, sentences):\n",
    "        filtered = []\n",
    "        \n",
    "        for sentence in sentences.values:\n",
    "            filtered.append([])\n",
    "            for word in sentence:\n",
    "                # for each word in sentence check if it's toxic\n",
    "                if word not in self.toxic_words:  # ignore if it's toxic\n",
    "                    filtered[-1].append(word)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def update_params(self, std: float = None, mean: float = None, n_occurences: int = None, recalculate: bool = True):\n",
    "        # update any parameter\n",
    "        if std is not None:\n",
    "            self.std = std\n",
    "        if mean is not None:\n",
    "            self.mean = mean\n",
    "        if n_occurences is not None:\n",
    "            self.n_occurences = n_occurences\n",
    "        \n",
    "        # update toxic words if needed\n",
    "        if recalculate:\n",
    "            self.__determine_toxic()\n",
    "    \n",
    "    def get_toxic_words(self):\n",
    "        return self.toxic_words\n",
    "    \n",
    "    def __determine_toxic(self):\n",
    "        self.toxic_words = set()\n",
    "        \n",
    "        # determine what words satisfy our toxicity requirements\n",
    "        for word, tox_levels in self.word_tox.items():\n",
    "            if (\n",
    "                tox_levels.std() < self.std and \n",
    "                tox_levels.mean() > self.mean and \n",
    "                tox_levels.size >= self.n_occurences\n",
    "               ):\n",
    "                self.toxic_words.add(word)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb51461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found toxic words: 128\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = ToxicWordRemover(std=0.2, mean=0.6, n_occurences=20)\n",
    "model.fit(X_train, y_train, with_scores=True)\n",
    "\n",
    "print('Found toxic words:', len(model.get_toxic_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4454b34",
   "metadata": {},
   "source": [
    "# Make predictions and validate them\n",
    "\n",
    "To validate model I will use the same approach as defined in the initial paper (check `ToxicityMeasuring` for more information). Main idea is to get toxic scores for each message and then calculate basic statistics (such as mean/std) to identify how low toxicity becomes after model predictions. If theory `1.4` works, we will see decrease in such values compared to initial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b3bc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'minute',\n",
       " 'she',\n",
       " \"'s\",\n",
       " 'my',\n",
       " ',',\n",
       " 'uh',\n",
       " ',',\n",
       " 'my',\n",
       " 'little',\n",
       " 'girl',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'the',\n",
       " 'next',\n",
       " 'minute',\n",
       " 'she',\n",
       " \"'s\",\n",
       " 'telling',\n",
       " 'me',\n",
       " 'to',\n",
       " 'go',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " ',',\n",
       " 'screw',\n",
       " 'myself',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and show example\n",
    "predictions = model.predict(X_test.message)\n",
    "\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cd758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 20:36:59.954415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 20:37:00.048101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-21 20:37:00.048116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-21 20:37:00.066238: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 20:37:00.430741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-21 20:37:00.430792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-21 20:37:00.430798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import all required libraries for validation\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# initialize tokenizer and model from s-nlp/detox repository\n",
    "model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc23b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 656/656 [15:19<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# define batch size and join words in messages\n",
    "batch_size = 64\n",
    "answers = [' '.join(words) for words in predictions]\n",
    "scores = []\n",
    "\n",
    "for i in tqdm(range((len(answers) + batch_size - 1) // batch_size)):\n",
    "    batch = answers[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "    # run sample batch from tokenizer & model (and calculate results)\n",
    "    tokens = tokenizer(text=batch, return_tensors='pt', padding=True)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        logits = model(**tokens).logits\n",
    "    scores.extend(list(torch.softmax(logits, -1)[:, 1].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b47aced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18570.,  1140.,   621.,   469.,   468.,   495.,   532.,   821.,\n",
       "         1491., 17343.]),\n",
       " array([3.27214839e-05, 9.99860168e-02, 1.99939311e-01, 2.99892604e-01,\n",
       "        3.99845898e-01, 4.99799192e-01, 5.99752486e-01, 6.99705780e-01,\n",
       "        7.99659073e-01, 8.99612367e-01, 9.99565661e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True)\n",
    "\n",
    "axs[1].set_title('Expected scores')\n",
    "axs[1].hist(y_test.tox_score)\n",
    "\n",
    "axs[0].set_title('Toxicity scores of predictions')\n",
    "axs[0].hist(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4861aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \t/ mean / std\n",
      "Initial:  0.9665 0.0489\n",
      "Resulted: 0.4864 0.4607\n",
      "Expected: 0.0199 0.0384\n"
     ]
    }
   ],
   "source": [
    "scores = np.array(scores)\n",
    "\n",
    "\n",
    "def print_stats(arr, start: str = \"\", round_lim: int = 4):\n",
    "    mean = round(float(arr.mean()), round_lim)\n",
    "    std = round(float(arr.std()), round_lim)\n",
    "    print(start + f\"{mean} {std}\")\n",
    "\n",
    "\n",
    "print('Type \\t/ mean / std')\n",
    "print_stats(X_test.tox_score, 'Initial:  ')\n",
    "print_stats(scores, 'Resulted: ')\n",
    "print_stats(y_test.tox_score, 'Expected: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea209f",
   "metadata": {},
   "source": [
    "# Outcomes of the session\n",
    "\n",
    "We can see that our baseline model reduced toxicity from high to low on almost half of the sentences. Which is proving out hypothesys 1.4 seems to be right. However there is also other half of messages that are still defined as toxic even after curse/high-correlation words removal. For that reason, we should test another solution (for example any architecture analyzed in `ArchitectureAnalysis` notebook). For such reason, we can test hypothesis that deep-learning model with memory cells can reduce toxicity even lower. But for now, we achieved mean toxicity score drop from `0.9665` to `0.4864` (judging by `SkolkovoInstitute/roberta_toxicity_classifier`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9436f43",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "Notebook created by Polina Zelenskaya\\\n",
    "Innopolis University DS21-03\n",
    "\n",
    "Github: [github.com/cutefluffyfox](https://github.com/cutefluffyfox)\\\n",
    "Email: p.zelenskaya@innopolis.university\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bd555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
