{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d536b93",
   "metadata": {},
   "source": [
    "# Model exploration\n",
    "\n",
    "  \n",
    "\n",
    "Prerequirements to run this notebook:\n",
    "* download all libraries mentioned in `requirements.txt`\n",
    "* download [filtered ParaNMT-detox corpus dataset](https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip)\n",
    "* unzip archive via graphical interface (ui.py) or just by hands to a directory `../data/raw/filtered_paranmt/filtered.tsv`\n",
    "\n",
    "Basic information about the dataset\n",
    "* `reference` (str) - First item from the pair\n",
    "* `ref_tox` (float) - toxicity level of reference text\n",
    "* `translation` (str) - second item from the pair - paraphrazed version of the reference\n",
    "* `trn_tox` (float) - toxicity level of translation text\n",
    "* `similarity` (float) - cosine similarity of the texts\n",
    "* `lenght_diff` (float) - relative length difference between texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e22af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('../data/raw/filtered_paranmt/filtered.tsv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b92d15",
   "metadata": {},
   "source": [
    "# Preprocessing step\n",
    "\n",
    "I will use techniques 1.1-1.3 (from `LearningDataset` notebook) for preprocessing. Main idea is to split translation/reference to toxic/non-toxic columns (as they are mixed) and introduce some threasholds on simmilarity and toxicity.\n",
    "\n",
    "\n",
    "1.1 During data preprocessing introduce new features `toxic` and `non-toxic` based on `ref_tox` and `trn_tox` scores.\\\n",
    "1.2 Introduce `toxisity_difference` threashold duting preprocessing.\\\n",
    "1.3 Tune which `simmilarity` value to consider in order to save sence of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8bb935",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxisity_difference = 0.75\n",
    "simmilarity_rate = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63e0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries passed: 72.61%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tox_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tox_score\n",
       "0  if Alkar floods her with her mental waste, it ...   0.981983\n",
       "1                        you're becoming disgusting.   0.999039\n",
       "2                      well, we can spare your life.   0.985068\n",
       "3                       monkey, you have to wake up.   0.994215\n",
       "4                         I have orders to kill her.   0.999348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split words to toxic & non-toxic based on rate [1.1]\n",
    "tox_queries = []\n",
    "ntox_queries = []\n",
    "\n",
    "for tox_query, ntox_query, sim, len_diff, tox, ntox in df.values:\n",
    "    if tox < ntox:\n",
    "        tox, ntox = ntox, tox\n",
    "        tox_query, ntox_query = ntox_query, tox_query \n",
    "    \n",
    "    # add threasholds on toxisity_difference [1.2] and simmilarity rate [1.3]\n",
    "    if (tox - ntox) >= toxisity_difference and sim >= simmilarity_rate:\n",
    "        tox_queries.append((tox_query, tox))\n",
    "        ntox_queries.append((ntox_query, ntox))\n",
    "\n",
    "print(f'Queries passed: {round(100 * len(tox_queries) / df.shape[0], 2)}%')\n",
    "\n",
    "# convert processed data to dataframes\n",
    "tox = pd.DataFrame(tox_queries, columns=['message', 'tox_score'])\n",
    "non_tox = pd.DataFrame(ntox_queries, columns=['message', 'tox_score'])\n",
    "\n",
    "tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899c87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "\n",
    "# tokenize_fn = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def tokenize_dataset(data: pd.DataFrame, spacy_tokenizer: str = 'en_core_web_sm'):\n",
    "    tokenize_fn = spacy.load(spacy_tokenizer)\n",
    "    \n",
    "    tokenized, tox_scores = [], []\n",
    "    for message, tox_score in tqdm(data.values):\n",
    "        tokenized.append([str(token) for token in tokenize_fn(message.lower())])\n",
    "        tox_scores.append(tox_score)\n",
    "    \n",
    "    new_data = pd.DataFrame(columns=['message', 'tox_score'])\n",
    "    new_data.message = tokenized\n",
    "    new_data.tox_score = tox_scores\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def count_words(data: pd.DataFrame) -> Counter:\n",
    "    data = data.copy()\n",
    "    \n",
    "    counter = Counter()\n",
    "\n",
    "    for tokens in tqdm(data.message):\n",
    "        for token in tokens:\n",
    "            counter[token] += 1\n",
    "    \n",
    "    return counter\n",
    "\n",
    "def delete_low_frequency_inplace(counter: Counter, threshold: int = 10):\n",
    "    import gc\n",
    "    \n",
    "    for (elem, freq) in list(counter.items()):\n",
    "        if freq < threshold:\n",
    "            del counter[elem]\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db385d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(counter: Counter, print_info: bool = True):\n",
    "    PAD_TOKEN = \"<PAD>\"\n",
    "    UNK_TOKEN = \"<UNK>\"\n",
    "    SOS_TOKEN = \"<SOS>\"\n",
    "    EOS_TOKEN = \"<EOS>\"\n",
    "\n",
    "    SPECIALS = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
    "\n",
    "    tox_vocab = vocab(counter, specials=SPECIALS)\n",
    "\n",
    "    tox_vocab.set_default_index(tox_vocab[UNK_TOKEN])\n",
    "\n",
    "    if print_info:\n",
    "        print(\"Number of tokens: {}\".format(len(tox_vocab)))\n",
    "    \n",
    "    return tox_vocab\n",
    "\n",
    "\n",
    "def save_vocab(vocab, filename: str = None):\n",
    "    if filename is None:\n",
    "        filename = f'spacy-processed-vocab-{len(vocab)}.pth'\n",
    "    torch.save(vocab, filename)\n",
    "    print(f'Succesfully saved vocab as `{filename}`')\n",
    "\n",
    "\n",
    "def load_vocab(filename: str):\n",
    "    return torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132428e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "tokenized_tox = pd.read_csv('tokenized-tox.csv', index_col=0)\n",
    "tokenized_non_tox = pd.read_csv('tokenized-non-tox.csv', index_col=0)\n",
    "\n",
    "tokenized_tox.message = tokenized_tox.message.apply(ast.literal_eval)\n",
    "tokenized_non_tox.message = tokenized_non_tox.message.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1528cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 838990/838990 [00:02<00:00, 378257.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 90026\n",
      "Number of words after removing low frequency: 8243\n",
      "Number of tokens: 8247\n",
      "Succesfully saved vocab as `full-words-vocab-40.pth`\n"
     ]
    }
   ],
   "source": [
    "whole_dataset = pd.concat([tokenized_tox, tokenized_non_tox])\n",
    "\n",
    "word_counter = count_words(whole_dataset)\n",
    "\n",
    "print('Number of unique words:', len(word_counter))\n",
    "threshold = 40  # 50 works fine with 7121 words!\n",
    "delete_low_frequency_inplace(word_counter, threshold=threshold)\n",
    "print('Number of words after removing low frequency:', len(word_counter))\n",
    "\n",
    "word_vocab = create_vocab(word_counter)\n",
    "save_vocab(word_vocab, f'full-words-vocab-{threshold}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8debbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 345600\n",
      "Test size: 38400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tokenized_tox\n",
    "y = tokenized_non_tox\n",
    "\n",
    "# split data to train/test\n",
    "    dataset_lim = 16000 * 24 # 1 minute is approximately 16k, so let's make epoch approximately 30 minutes *24\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:dataset_lim], y[:dataset_lim], test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print('Train size:', X_train.shape[0])\n",
    "print('Test size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3846a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocab(f'full-words-vocab-{threshold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd635105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab.vocab import Vocab\n",
    "\n",
    "\n",
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 tokenized_tox_data: pd.DataFrame, \n",
    "                 tokenized_non_tox_data: pd.DataFrame,\n",
    "                 vocab: Vocab,\n",
    "                 max_size: int = 150\n",
    "                ):\n",
    "        self.max_size = max_size\n",
    "        self.tox_data = tokenized_tox_data\n",
    "        self.non_tox_data = tokenized_non_tox_data\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def _get_sentence(self, index: int, is_toxic: bool) -> list[int]:\n",
    "        # retrieves sentence from dataset by index\n",
    "        if is_toxic:\n",
    "            sent = ['<SOS>'] + self.tox_data.message[index] + ['<EOS>']\n",
    "        else:\n",
    "            sent = ['<SOS>'] + self.non_tox_data.message[index] + ['<EOS>']\n",
    "        \n",
    "        if len(sent) <= self.max_size:\n",
    "            sent.extend(['<PAD>'] * (self.max_size - len(sent)))\n",
    "        else:\n",
    "            sent = sent[:self.max_size - 1] + ['<EOS>']\n",
    "        \n",
    "        return self.vocab(sent)\n",
    "    \n",
    "    def __getitem__(self, index) -> tuple[list[int], list[int]]:\n",
    "        return self._get_sentence(index, is_toxic=True), self._get_sentence(index, is_toxic=False)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.tox_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "626bfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 75\n",
    "\n",
    "train_dataset = ToxicDataset(X_train, y_train, vocab, max_size=max_size)\n",
    "test_dataset = ToxicDataset(X_test, y_test, vocab, max_size=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dd767ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "\n",
    "def collate_batch(batch: list):\n",
    "    toxic, non_toxic = [], []\n",
    "    for (tox, non_tox) in batch:\n",
    "        toxic.append(torch.tensor(tox))\n",
    "        non_toxic.append(torch.tensor(non_tox))\n",
    "    return torch.stack(toxic), torch.stack(non_toxic)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df87523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb7626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db457d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c01134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84756422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746a8d18",
   "metadata": {},
   "source": [
    "# Model itself \n",
    "\n",
    "Code structure was taken from [pytorch seq2seq tutorial](https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb) with some modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f900894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "                \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a15663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DSkBart(nn.Module):\n",
    "    def __init__(self, vocab_size: int, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        ENC_EMB_DIM = 128\n",
    "        DEC_EMB_DIM = 128\n",
    "        ENC_HID_DIM = 256\n",
    "        DEC_HID_DIM = 256\n",
    "        ENC_DROPOUT = 0.5\n",
    "        DEC_DROPOUT = 0.5\n",
    "\n",
    "        self.attention = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "        self.encoder = Encoder(vocab_size, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "        self.decoder = Decoder(vocab_size, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, self.attention)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c03f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,119,799 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DSkBart(len(vocab), device).to(device)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb95554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSkBart(\n",
       "  (attention): Attention(\n",
       "    (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(8247, 128)\n",
       "    (rnn): GRU(128, 256, bidirectional=True)\n",
       "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(8247, 128)\n",
       "    (rnn): GRU(640, 256)\n",
       "    (fc_out): Linear(in_features=896, out_features=8247, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0010a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "PAD_IDX = vocab['<PAD>']\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a862dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(tqdm(iterator)):\n",
    "        tox, non_tox = batch\n",
    "        tox, non_tox = tox.to(device), non_tox.to(device)\n",
    "        tox, non_tox = tox.T, non_tox.T\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(tox, non_tox)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        non_tox = non_tox[1:].flatten()\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, non_tox)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aba8b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(iterator)):\n",
    "            tox, non_tox = batch\n",
    "            tox, non_tox = tox.to(device), non_tox.to(device)\n",
    "            tox, non_tox = tox.T, non_tox.T\n",
    "\n",
    "            output = model(tox, non_tox, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            non_tox = non_tox[1:].flatten()\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, non_tox)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96bb0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [30:13<00:00,  1.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 4.306 | Train PPL:  74.171\n",
      "\t Val. Loss: 4.276 |  Val. PPL:  71.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [30:55<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02\n",
      "\tTrain Loss: 3.274 | Train PPL:  26.420\n",
      "\t Val. Loss: 4.030 |  Val. PPL:  56.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:03<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:30<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03\n",
      "\tTrain Loss: 3.008 | Train PPL:  20.245\n",
      "\t Val. Loss: 4.036 |  Val. PPL:  56.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:13<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:31<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04\n",
      "\tTrain Loss: 2.883 | Train PPL:  17.863\n",
      "\t Val. Loss: 3.999 |  Val. PPL:  54.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:13<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:32<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05\n",
      "\tTrain Loss: 2.799 | Train PPL:  16.432\n",
      "\t Val. Loss: 3.973 |  Val. PPL:  53.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:07<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:32<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06\n",
      "\tTrain Loss: 2.741 | Train PPL:  15.508\n",
      "\t Val. Loss: 3.941 |  Val. PPL:  51.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:09<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:30<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07\n",
      "\tTrain Loss: 2.700 | Train PPL:  14.881\n",
      "\t Val. Loss: 3.926 |  Val. PPL:  50.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:00<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:29<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08\n",
      "\tTrain Loss: 2.661 | Train PPL:  14.311\n",
      "\t Val. Loss: 3.988 |  Val. PPL:  53.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:02<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:31<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09\n",
      "\tTrain Loss: 2.630 | Train PPL:  13.879\n",
      "\t Val. Loss: 3.985 |  Val. PPL:  53.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:06<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Loss: 2.605 | Train PPL:  13.527\n",
      "\t Val. Loss: 3.929 |  Val. PPL:  50.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:02<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n",
      "\tTrain Loss: 2.585 | Train PPL:  13.269\n",
      "\t Val. Loss: 3.989 |  Val. PPL:  53.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:32<00:00,  1.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:33<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n",
      "\tTrain Loss: 2.562 | Train PPL:  12.960\n",
      "\t Val. Loss: 4.002 |  Val. PPL:  54.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:10<00:00,  1.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:31<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "\tTrain Loss: 2.550 | Train PPL:  12.807\n",
      "\t Val. Loss: 3.965 |  Val. PPL:  52.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2700/2700 [31:04<00:00,  1.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:31<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "\tTrain Loss: 2.537 | Train PPL:  12.637\n",
      "\t Val. Loss: 3.992 |  Val. PPL:  54.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N_EPOCHS = 14\n",
    "CLIP = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, test_dataloader, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f7c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = DSkBart(len(vocab))\n",
    "best_model.load_state_dict(torch.load('best-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9dd21e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text: pd.DataFrame, vocab, max_size: int, already_tokenized: bool = False):\n",
    "    tokenized_text = tokenize_dataset(text) if not already_tokenized else text\n",
    "    text_dataset = ToxicDataset(tokenized_text, tokenized_text, vocab, max_size=max_size)\n",
    "    text_dataloader = torch.utils.data.DataLoader(dataset=text_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(text_dataloader)):\n",
    "            tox, non_tox = batch\n",
    "            tox, non_tox = tox.to(device), non_tox.to(device)\n",
    "            tox, non_tox = tox.T, non_tox.T\n",
    "\n",
    "            output = model(tox, non_tox, 0) #turn off teacher forcing\n",
    "            \n",
    "            words.extend(output.argmax(dim=2).T.cpu().detach().tolist())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fdccc8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tox_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate you, bitch</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love you</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now you're getting nasty</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is dumb</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    message  tox_score\n",
       "0         I hate you, bitch        0.5\n",
       "1                i love you        0.5\n",
       "2  Now you're getting nasty        0.5\n",
       "3              This is dumb        0.5"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame(columns=['message', 'tox_score'])\n",
    "text_df.message = ['I hate you, bitch', 'i love you', \"Now you're getting nasty\", 'This is dumb']\n",
    "text_df.tox_score = 0.5\n",
    "\n",
    "\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a902346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 210.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    }
   ],
   "source": [
    "text_vocab_ids = inference(best_model, text_df, vocab, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cba3ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_vocab(text: list[list[int]], vocab):\n",
    "    for line in text:\n",
    "        yield vocab.lookup_tokens(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7bbb22dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> i hate you , <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "<PAD> i love you love <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "<PAD> now you 're getting ugly . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "<PAD> this is crazy . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "print(*[' '.join(words) for words in from_vocab(text_vocab_ids, vocab)], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddb8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cc3454ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import all required libraries for validation\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# initialize tokenizer and model from s-nlp/detox repository\n",
    "toxic_model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n",
    "\n",
    "toxic_tokenizer = RobertaTokenizer.from_pretrained(toxic_model_name)\n",
    "toxic_model = RobertaForSequenceClassification.from_pretrained(toxic_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2c32a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\u001b[A\n",
      " 33%|█████████████████████████████████████████████████████████████████▎                                                                                                                                  | 1/3 [00:00<00:01,  1.46it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\u001b[A\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 2/3 [00:01<00:00,  1.80it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:34<00:00, 31.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# define batch size and join words in messages\n",
    "# batch_size = 64\n",
    "answers = []\n",
    "scores = []\n",
    "\n",
    "X_test.message = X_test.message.apply(lambda words: list(map(str, words)))\n",
    "\n",
    "for i in tqdm([0, 1, 2]): # tqdm(range(int(np.ceil(X_test.shape[0] /  batch_size)))):\n",
    "    X_test_subsample = X_test[i * batch_size:(i + 1) * batch_size]\n",
    "    X_test_subsample = X_test_subsample.reset_index(drop=True)\n",
    "    \n",
    "    test_vocab_inds = inference(best_model, X_test_subsample, vocab, max_size, already_tokenized=True)\n",
    "    answers.extend([' '.join(words) for words in from_vocab(test_vocab_inds, vocab)])\n",
    "\n",
    "\n",
    "for i in tqdm([0, 1, 2]): # tqdm(range(int(np.ceil(X_test.shape[0] / batch_size)))):\n",
    "    batch = answers[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "    # run sample batch from tokenizer & model (and calculate results)\n",
    "    tokens = toxic_tokenizer(text=batch, return_tensors='pt', padding=True)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        logits = toxic_model(**tokens).logits\n",
    "    scores.extend(list(torch.softmax(logits, -1)[:, 1].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e040a249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([366.,   2.,   3.,   1.,   2.,   0.,   4.,   0.,   2.,   4.]),\n",
       " array([4.68782091e-05, 9.89068598e-02, 1.97766840e-01, 2.96626806e-01,\n",
       "        3.95486802e-01, 4.94346768e-01, 5.93206763e-01, 6.92066729e-01,\n",
       "        7.90926695e-01, 8.89786720e-01, 9.88646686e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True)\n",
    "\n",
    "axs[1].set_title('Expected scores')\n",
    "axs[1].hist(y_test.tox_score)\n",
    "\n",
    "axs[0].set_title('Toxicity scores of predictions')\n",
    "axs[0].hist(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fb91fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \t/ mean / std\n",
      "Initial:  0.9668 0.0484\n",
      "Resulted: 0.0341 0.138\n",
      "Expected: 0.0204 0.0391\n"
     ]
    }
   ],
   "source": [
    "scores = np.array(scores)\n",
    "\n",
    "\n",
    "def print_stats(arr, start: str = \"\", round_lim: int = 4):\n",
    "    mean = round(float(arr.mean()), round_lim)\n",
    "    std = round(float(arr.std()), round_lim)\n",
    "    print(start + f\"{mean} {std}\")\n",
    "\n",
    "\n",
    "print('Type \\t/ mean / std')\n",
    "print_stats(X_test.tox_score, 'Initial:  ')\n",
    "print_stats(scores, 'Resulted: ')\n",
    "print_stats(y_test.tox_score, 'Expected: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5191b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca2320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae09efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8663b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b555ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c183f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e7f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa7f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493bcf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e5842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
